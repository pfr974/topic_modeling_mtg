{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling and Magic: The Gathering\n",
    "\n",
    "This notebook is to be read along this blog post. Here I have used [all the Legacy decks registered in 2020 on mtgtop8](https://www.mtgtop8.com/format?f=LE&meta=199). I obtained this file from a companion project: [spider_mtg](https://github.com/pfr974/spider_mtg) and have done the same for other years here: https://github.com/pfr974/mtg-legacy-data. Please, feel free to use them and also point out mistakes if you see some (シ_ _)シ \n",
    "\n",
    "## Prerequisites:\n",
    "\n",
    "You will need the following librairies:\n",
    "- [NumPy](https://numpy.org/doc/stable/user/quickstart.html) \n",
    "- [six](https://six.readthedocs.io/) \n",
    "- [gensim](https://radimrehurek.com/gensim/)\n",
    "- [pyLDAvis](https://pyldavis.readthedocs.io/en/latest/readme.html#installation)\n",
    "\n",
    "## Acknowledgments ೕ(･ㅂ･ ):\n",
    "\n",
    "The starting point for this project was reading a while ago [this article](https://towardsdatascience.com/finding-magic-the-gathering-archetypes-with-latent-dirichlet-allocation-729112d324a6) by [hlynurd](https://github.com/hlynurd). Please give it a read and check [his notebook](https://github.com/hlynurd/lda-for-magic)!\n",
    "\n",
    "Both [hlynurd](https://github.com/hlynurd) and myself pretty much followed [this tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html) which explains the core concepts needed to understand and use [gensim](https://radimrehurek.com/gensim/).\n",
    "\n",
    "## Disclaimer (`Д´)ゞ:\n",
    "\n",
    "The information presented here about Magic: The Gathering is copyrighted by Wizards of the Coast. This project is not produced, endorsed, supported, or affiliated with Wizards of the Coast.\n",
    "\n",
    "https://www.mtgtop8.com/ is the source of my data. This project would not have been possible without their amazing work!\n",
    "\n",
    "**I by no mean claim to be a data science expert. Feel free to critize if you don't agree with something**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Adapted from: https://github.com/hlynurd/lda-for-magic/blob/master/lda-mtg-notebook.ipynb\n",
    "\n",
    "#import pandas as pd\n",
    "#import itertools as it\n",
    "\n",
    "import gensim \n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.models.hdpmodel import HdpModel\n",
    "from gensim.models.wrappers import LdaVowpalWabbit, LdaMallet\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import re \n",
    "from six import iteritems\n",
    "\n",
    "import logging\n",
    "try:\n",
    "    import pyLDAvis.gensim\n",
    "except ImportError:\n",
    "    ValueError(\"SKIP: please install pyLDAvis\")\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and processing the data\n",
    "\n",
    "The documents (decklists) are stored in a single file, one document per line. We have 75 cards in a deck: 60 cards mainboard, 15 cards sideboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"3  Bayou 1  Dryad Arbor 2  Marsh Flats 3  Misty Rainforest 3  Polluted Delta 1  Snow-Covered Swamp 3  Underground Sea 4  Verdant Catacombs 4  Bloodghast 4  Gravecrawler 4  Hedron Crab 4  Hogaak, Arisen Necropolis 2  Putrid Imp 4  Stitcher\\\\'s Supplier 4  Vengevine 4  Cabal Therapy 2  Careful Study 4  Altar of Dementia 4  Bridge from Below 3  Chain of Vapor 4  Force of Vigor 4  Leyline of the Void 1  Oko, Thief of Crowns 3  Thoughtseize \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('single_legacy_2020.txt', 'r') as f:\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to know the set of all words that will be used in the corpus, i.e. the **vocabulary**. Here, it corresponds to the card names. Fortunately, gensim has a class which can do that: **gensim.corpora.Dictionary**. We construct a memory friendly dictionary without loading all the decklists into memory; see [core concepts of gensim](https://radimrehurek.com/gensim/auto_examples/core/run_corpora_and_vector_spaces.html). Note that we also remove the card names that only appear once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(1639 unique tokens: ['', 'Altar of Dementia', 'Bayou', 'Bloodghast', 'Bridge from Below']...) from 3718 documents (total 124854 corpus positions)\n",
      "DEBUG:gensim.corpora.dictionary:rebuilding dictionary, shrinking gaps\n",
      "DEBUG:gensim.corpora.dictionary:rebuilding dictionary, shrinking gaps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1206 unique tokens: ['', 'Altar of Dementia', 'Bayou', 'Bloodghast', 'Bridge from Below']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary([x.strip() for x in re.split(r\"[\\d]+\", line.replace(\"\\\"\", \"\"))] for line in open('single_legacy_2020.txt'))\n",
    "once_ids = [tokenid for tokenid, docfreq in iteritems(dictionary.dfs) if docfreq == 1]\n",
    "dictionary.filter_tokens(once_ids)  # remove cards that appear only once\n",
    "dictionary.compactify()  # remove gaps in id sequence after words that were removed\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a vocabulary of 1206 unique card names.\n",
    "\n",
    "Now, in terms of preprocessing steps, we do not have as much to do as for, let's say, a collection of newspaper articles. No stop words here! Looking at what we have above for a line, we need to remove:\n",
    "- the **\\\"** character at the start and end of the line;\n",
    "- the number of cards.\n",
    "\n",
    "SImilarly to the vocabulary dictionary, we want a **memory friendly corpus**. Following [the core concepts of gensim](https://radimrehurek.com/gensim/auto_examples/core/run_corpora_and_vector_spaces.html) and [hlynurd's original notebook](https://github.com/hlynurd/lda-for-magic), we define a class **MyCorpus** that yield documents and also preprocess them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for line in open('single_legacy_2020.txt'):\n",
    "            decklist = line.replace(\"\\\"\", \"\") # remove start and end tokens\n",
    "            decklist = re.split(r\"([\\d]+)\", decklist) # split by numbers and card names\n",
    "            decklist = [x.strip() for x in decklist] # remove whitespace\n",
    "            decklist = list(filter(None, decklist)) # remove empty words\n",
    "            cleaned_decklist = [] \n",
    "            for i in range(int(len(list(decklist))/2)):\n",
    "                for j in range(int(len(list(decklist[i*2])))):\n",
    "                    cleaned_decklist.append(decklist[i*2+1])\n",
    "            yield dictionary.doc2bow(cleaned_decklist)\n",
    "    \n",
    "corpus_memory_friendly = MyCorpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gensim corpus contains the word id and its frequency. With the line <code> <i>yield dictionary.doc2bow(cleaned_decklist)</i> </code>, we convert a list of tokenized words via a dictionary to their ids and yield the resulting bag of words (bow) corpus. To simplify, here we are counting how many time a card name, via its **id**, appears in a decklist. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "We can now proceed and search for different archetypes using LDA. We have below a function called <code><i>compute_models_coherence</i></code> to do so. It returns a list of models and u_mass coherence values for various number of topics. **The coherence allows to quantitatively evaluate how good a model is**, how it can find patterns in the corpus. Sure, we could simply read all the weighted card names associated to a topic to see if they make sense but I don't think you would like to go through hundreds of topics. Morever, human interpretation is subjective. To compare our different models, we will therefore investigate their coherence score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_models_coherence(dictionary, corpus_memory_friendly, model, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Return topic modeling models and u_mass coherence values for various number of topics.\n",
    "    For more info about coherence, see:\n",
    "    - https://radimrehurek.com/gensim/models/coherencemodel.html\n",
    "    - https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    model : the topic modeling model (lda or nmf)\n",
    "    start: Starting number of topics\n",
    "    limit : Max number of topics\n",
    "    step: increment\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA or NMF topic models\n",
    "    coherence_values : u_mass Coherence values corresponding to the LDA or NMF model with respective number of topics\n",
    "    \"\"\"\n",
    "    \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    \n",
    "    # We set iterations and passes to the same number\n",
    "    iterations = 50\n",
    "    # See https://groups.google.com/g/gensim/c/z0wG3cojywM to read about the difference between passes and iterations \n",
    "    \n",
    "    np.random.seed(1) # For reproductivity\n",
    "    unique_cards = len(dictionary.keys())\n",
    "    \n",
    "    if model == 'nmf':\n",
    "        \n",
    "        for archetypes in range(start, limit, step):\n",
    "        \n",
    "            model= Nmf(corpus=corpus_memory_friendly, num_topics=archetypes,id2word=dictionary,chunksize=2000,\n",
    "                                     passes=iterations,kappa=.1,minimum_probability=0.01,w_max_iter=300,\n",
    "                                     w_stop_condition=0.0001,h_max_iter=100,\n",
    "                                     h_stop_condition=0.001,eval_every=10,\n",
    "                                     normalize=True,random_state=np.random.seed(1))\n",
    "        \n",
    "            model_list.append(model)\n",
    "            coherencemodel = CoherenceModel(model=model, corpus=corpus_memory_friendly, dictionary=dictionary, coherence='u_mass')\n",
    "            coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    if model == 'lda':\n",
    "        \n",
    "        for archetypes in range(start, limit, step):\n",
    "        \n",
    "            alpha_prior = [1.0 / archetypes] * archetypes\n",
    "            beta_prior = [1.0 / archetypes] * unique_cards\n",
    "        \n",
    "            model=gensim.models.ldamodel.LdaModel(corpus=corpus_memory_friendly, id2word=dictionary, \n",
    "                                                  num_topics=archetypes, passes=iterations, \n",
    "                                                  alpha = alpha_prior, eta = beta_prior)\n",
    "            model_list.append(model)\n",
    "            coherencemodel = CoherenceModel(model=model, corpus=corpus_memory_friendly, dictionary=dictionary, coherence='u_mass')\n",
    "            coherence_values.append(coherencemodel.get_coherence())\n",
    "    \n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the lda model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_lda, coherence_values_lda = compute_coherence_values(dictionary=dictionary,\n",
    "                                                                corpus_memory_friendly = corpus_memory_friendly, \n",
    "                                                                model='lda', start=2, limit=20, step=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
